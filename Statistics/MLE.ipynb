{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fa2c12",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimate (MLE)\n",
    "\n",
    "The goal is to obtain a MLE for a simple problem. \n",
    "\n",
    "Estimate $\\mu$ and $\\sigma^2$ from $X_{n \\times 1}$. \n",
    "\n",
    "Likelihood $\\mathcal{L}_{n}(\\mu,\\sigma^2) = \\mathcal{L}_{n}(\\mu,\\sigma^2|X) = f(X|\\mu,\\sigma^2)$\n",
    "\n",
    "Assuming each $x_i$ are *independent random variables*\n",
    "\n",
    "$ \\implies \\mathcal{L}_{n}(\\mu,\\sigma^2|X) = \\Pi_{i=1}^{n} p(x_i|\\mu,\\sigma^2)$\n",
    "\n",
    "Assuming $x_i$ are *identically* distributed as normal distributions, \n",
    "\n",
    "$ \\implies \\mathcal{L}_{n}(\\mu,\\sigma^2|X) = \\Pi_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x_i-\\mu)^2}{2 \\sigma^2}}$\n",
    "\n",
    "\n",
    "\n",
    "### Our MLE(stimates) $\\mu_*$, $\\sigma_*^2$\n",
    "$$\\{\\mu_*, \\sigma_*^2\\} = \\argmax_{\\mu,\\sigma^2} \\mathcal{L}_{n}(\\mu,\\sigma^2|X) $$\n",
    "\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\\implies \\{\\mu_*, \\sigma_*^2\\}  &= \\argmax_{\\mu,\\sigma^2} \\Pi_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x_i-\\mu)^2}{2 \\sigma^2}} \\\\\n",
    "                                &= \\argmax_{\\mu,\\sigma^2} (\\frac{1}{\\sqrt{2\\pi\\sigma^2}})^n e^{\\sum_{i=1}^n -\\frac{(x_i-\\mu)^2}{2 \\sigma^2}}\n",
    "\n",
    "\\end{aligned}                            \n",
    " We need to make a harmless and necessary assumption that $\\sigma^2 \\neq 0$.\n",
    "\n",
    " \n",
    "### Introducing Log-likelihood (a very common \"trick\")\n",
    "*Why introduce* $\\log$\n",
    "* Any function is easy to optimize if it is convex. One can simply find the extremums and one of it must be the optimal value.\n",
    "* Difficult to analyze a function for convexity (think about getting the $\\frac{\\partial f}{\\partial \\mu}$) that is all in multiplication - $a_1(\\mu,\\sigma^2) \\times a_2(\\mu,\\sigma^2) \\times ... \\times a_n(\\mu,\\sigma^2)$.\n",
    "* Notice that all the functions $a_i$ s are positive functions (since they are pdfs). \n",
    "* Also, $\\log$ is strictly increasing function - so maximizing $log$ likelihood is same as maximizing likelihood. \n",
    "* $log$ converts the multiplication to addition  - $a_1(\\mu,\\sigma^2) + a_2(\\mu,\\sigma^2) + ... + a_n(\\mu,\\sigma^2)$ \n",
    "and convenient to calculate derivatives ($\\frac{\\partial f}{\\partial \\mu}$).\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\\implies \\{\\mu_*, \\sigma_*^2\\} &= \\argmax_{\\mu,\\sigma^2} \\log (\\frac{1}{\\sqrt{2\\pi\\sigma^2}})^n e^{\\sum_{i=1}^n -\\frac{(x_i-\\mu)^2}{2 \\sigma^2}} \\\\\n",
    "                               &= \\argmax_{\\mu,\\sigma^2} \\frac{n}{2}\\log(\\frac{1}{2\\pi\\sigma^2}) -   \\sum_{i=1}^n \\frac{(x_i-\\mu)^2}{2 \\sigma^2} \\\\ \n",
    "                               &= \\argmax_{\\mu,\\sigma^2} -\\frac{n}{2}\\log(2\\pi\\sigma^2) -   \\sum_{i=1}^n \\frac{(x_i-\\mu)^2}{2 \\sigma^2}\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "### Estimating $\\mu_*$ \n",
    "The above function is concave in $\\mu$ (Ideally, we need to do a second derivative test - but I said this directly because it is just negative of sum of \"squares\"). So, the first derivative zero should give the \"extremum\". \n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    " \\frac{\\partial log \\mathcal{L}_n(\\mu,\\sigma^2|X)}{\\partial \\mu} = &\\sum_{i=1}^n (2)(-1)\\frac{x_i - \\mu}{2 \\sigma^2} = 0 \\\\\n",
    " \\implies &\\sum_{i=1}^n x_i - \\mu_* = 0 \\\\\n",
    " \\implies &\\sum_{i=1}^n x_i = n\\mu_* \\\\\n",
    " \\implies  &\\mu_* = \\frac{1}{n}\\sum_{i=1}^n x_i\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0926fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b16b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true = 4.3\n",
    "sigma_true = 2.1\n",
    "\n",
    "\n",
    "X = np.random.normal(mu_true, sigma_true, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statistics_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
