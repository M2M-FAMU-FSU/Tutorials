{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgmrWqRujLo1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "from torch_geometric.nn import NNConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "import numpy as np\n",
        "# Example graph with 4 edges\n",
        "# edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long)\n",
        "\n",
        "# # Edge features (distance, conductivity, etc.)\n",
        "# edge_features = torch.tensor([[0.1, 1.5], [0.2, 1.0], [0.3, 0.8], [0.4, 1.2]], dtype=torch.float)\n",
        "\n",
        "# # Node features (3 features per node)\n",
        "# node_features = torch.rand(5, 3)\n",
        "\n",
        "# graph_data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running on Colab**\n",
        "*   Need to pip install torch_geometric\n",
        "*   Correct the filename as needed.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mppG47fBSvHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "filename = \"./sample_data/Initial_test.h5\"\n",
        "# T_output = []\n",
        "# edge_distances = []\n",
        "# edge_mappings = []\n",
        "# one_hot_features = []\n",
        "graphs = []\n",
        "\n",
        "with h5py.File(filename, \"r\") as f:\n",
        "    h5_graphs = list(f.keys())\n",
        "    # for key in f.keys():\n",
        "    for i in range(len(h5_graphs)):\n",
        "        print(h5_graphs[i])\n",
        "        graph = h5_graphs[i]\n",
        "\n",
        "        T_output = f[graph][\"Temperature\"][()]\n",
        "        edge_distances = (f[graph][\"edge_distance\"][()])\n",
        "        edge_mappings = f[graph][\"edge_mappings\"][()] - 1 #adjusting for Python Indexing\n",
        "        one_hot_features = f[graph][\"one_hot_features\"][()]\n",
        "\n",
        "        # print(T_output.shape)\n",
        "        # print(edge_distances.shape)\n",
        "        # print(edge_mappings.shape)\n",
        "        # print(one_hot_features.shape)\n",
        "\n",
        "        #\n",
        "\n",
        "        edge_mappings = edge_mappings.astype(np.int64)\n",
        "\n",
        "        graphs.append(Data(\n",
        "        x= torch.from_numpy(one_hot_features.reshape(-1,3)).float(),\n",
        "        edge_index=torch.from_numpy(edge_mappings.reshape(2,-1)),\n",
        "        edge_attr=torch.from_numpy(edge_distances.reshape(-1,1)).float(),  # 1 feature distance\n",
        "        y=torch.from_numpy(T_output.reshape(-1,1)).float()  # Target output for each node\n",
        "        ))\n",
        "\n",
        "loader = DataLoader(graphs, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3qKEbTMhtCc",
        "outputId": "22077959-9f7f-4213-d51f-2ae9a166dde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph_1\n",
            "graph_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeFeatureGNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, edge_feature_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Output size of edge_nn must match (hidden_dim * input_dim)\n",
        "        edge_nn_1 = Sequential(\n",
        "            Linear(edge_feature_dim, hidden_dim * input_dim),\n",
        "            # Linear(edge_feature_dim, edge_feature_dim),\n",
        "            ReLU()\n",
        "        )\n",
        "\n",
        "        edge_nn_2 = Sequential(\n",
        "            Linear(edge_feature_dim, hidden_dim * hidden_dim),\n",
        "            # Linear(edge_feature_dim, edge_feature_dim),\n",
        "            ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv1 = NNConv(input_dim, hidden_dim, edge_nn_1, aggr='mean')\n",
        "        self.conv2 = NNConv(hidden_dim, hidden_dim, edge_nn_2, aggr='mean')\n",
        "\n",
        "        self.fc = Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "        # print(x.shape)\n",
        "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
        "        # print(x.shape)\n",
        "        x = self.conv2(x, edge_index, edge_attr).relu()\n",
        "        return self.fc(x)\n",
        "\n",
        "# Dummy graph data setup\n",
        "# node_features = torch.rand(6, 3)  # 6 nodes with 3 features\n",
        "# edge_index = torch.tensor([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5]], dtype=torch.long)\n",
        "# edge_features = torch.rand(5, 2)  # 5 edges with 2 features\n",
        "\n",
        "# graph_data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
        "\n",
        "# model = EdgeFeatureGNN(input_dim=3, hidden_dim=8, edge_feature_dim=2, output_dim=1)\n",
        "# output = model(graph_data)\n",
        "# print(\"Node-level predictions shape:\", output.shape)"
      ],
      "metadata": {
        "id": "FnHVrVGpbZyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EdgeFeatureGNN(input_dim=3, hidden_dim=16, edge_feature_dim=1, output_dim=1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        out = model(batch)\n",
        "        loss = loss_fn(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_wSvfwSM3SB",
        "outputId": "5571b5a8-7051-4bc5-9a2d-5530bf3fa4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 37526260.0000\n",
            "Epoch 2, Loss: 37522704.0000\n",
            "Epoch 3, Loss: 37519088.0000\n",
            "Epoch 4, Loss: 37515284.0000\n",
            "Epoch 5, Loss: 37511248.0000\n",
            "Epoch 6, Loss: 37506924.0000\n",
            "Epoch 7, Loss: 37502260.0000\n",
            "Epoch 8, Loss: 37497192.0000\n",
            "Epoch 9, Loss: 37491672.0000\n",
            "Epoch 10, Loss: 37485588.0000\n",
            "Epoch 11, Loss: 37478864.0000\n",
            "Epoch 12, Loss: 37471352.0000\n",
            "Epoch 13, Loss: 37463016.0000\n",
            "Epoch 14, Loss: 37453768.0000\n",
            "Epoch 15, Loss: 37443548.0000\n",
            "Epoch 16, Loss: 37432248.0000\n",
            "Epoch 17, Loss: 37419788.0000\n",
            "Epoch 18, Loss: 37406064.0000\n",
            "Epoch 19, Loss: 37390980.0000\n",
            "Epoch 20, Loss: 37374360.0000\n",
            "Epoch 21, Loss: 37356148.0000\n",
            "Epoch 22, Loss: 37336096.0000\n",
            "Epoch 23, Loss: 37314048.0000\n",
            "Epoch 24, Loss: 37289976.0000\n",
            "Epoch 25, Loss: 37263692.0000\n",
            "Epoch 26, Loss: 37235088.0000\n",
            "Epoch 27, Loss: 37204004.0000\n",
            "Epoch 28, Loss: 37170284.0000\n",
            "Epoch 29, Loss: 37133764.0000\n",
            "Epoch 30, Loss: 37093952.0000\n",
            "Epoch 31, Loss: 37050852.0000\n",
            "Epoch 32, Loss: 37004312.0000\n",
            "Epoch 33, Loss: 36954160.0000\n",
            "Epoch 34, Loss: 36900204.0000\n",
            "Epoch 35, Loss: 36842256.0000\n",
            "Epoch 36, Loss: 36780108.0000\n",
            "Epoch 37, Loss: 36713576.0000\n",
            "Epoch 38, Loss: 36642204.0000\n",
            "Epoch 39, Loss: 36565632.0000\n",
            "Epoch 40, Loss: 36483860.0000\n",
            "Epoch 41, Loss: 36396664.0000\n",
            "Epoch 42, Loss: 36303832.0000\n",
            "Epoch 43, Loss: 36205156.0000\n",
            "Epoch 44, Loss: 36100440.0000\n",
            "Epoch 45, Loss: 35989456.0000\n",
            "Epoch 46, Loss: 35871804.0000\n",
            "Epoch 47, Loss: 35746644.0000\n",
            "Epoch 48, Loss: 35614284.0000\n",
            "Epoch 49, Loss: 35474524.0000\n",
            "Epoch 50, Loss: 35327152.0000\n"
          ]
        }
      ]
    }
  ]
}